{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Reporting_Airline</th>\n",
       "      <th>DOT_ID_Reporting_Airline</th>\n",
       "      <th>IATA_CODE_Reporting_Airline</th>\n",
       "      <th>Tail_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Div1WheelsOff</th>\n",
       "      <th>Div1TailNum</th>\n",
       "      <th>Div2Airport</th>\n",
       "      <th>Div2AirportID</th>\n",
       "      <th>Div2AirportSeqID</th>\n",
       "      <th>Div2WheelsOn</th>\n",
       "      <th>Div2TotalGTime</th>\n",
       "      <th>Div2LongestGTime</th>\n",
       "      <th>Div2WheelsOff</th>\n",
       "      <th>Div2TailNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>NW</td>\n",
       "      <td>19386</td>\n",
       "      <td>NW</td>\n",
       "      <td>N297US</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-05-28</td>\n",
       "      <td>FL</td>\n",
       "      <td>20437</td>\n",
       "      <td>FL</td>\n",
       "      <td>N946AT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-06-29</td>\n",
       "      <td>MQ</td>\n",
       "      <td>20398</td>\n",
       "      <td>MQ</td>\n",
       "      <td>N665MQ</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-08-31</td>\n",
       "      <td>DL</td>\n",
       "      <td>19790</td>\n",
       "      <td>DL</td>\n",
       "      <td>N6705Y</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2006-01-15</td>\n",
       "      <td>US</td>\n",
       "      <td>20355</td>\n",
       "      <td>US</td>\n",
       "      <td>N504AU</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate Reporting_Airline  \\\n",
       "0  1998        1      1           2          5  1998-01-02                NW   \n",
       "1  2009        2      5          28          4  2009-05-28                FL   \n",
       "2  2013        2      6          29          6  2013-06-29                MQ   \n",
       "3  2010        3      8          31          2  2010-08-31                DL   \n",
       "4  2006        1      1          15          7  2006-01-15                US   \n",
       "\n",
       "   DOT_ID_Reporting_Airline IATA_CODE_Reporting_Airline Tail_Number  ...  \\\n",
       "0                     19386                          NW      N297US  ...   \n",
       "1                     20437                          FL      N946AT  ...   \n",
       "2                     20398                          MQ      N665MQ  ...   \n",
       "3                     19790                          DL      N6705Y  ...   \n",
       "4                     20355                          US      N504AU  ...   \n",
       "\n",
       "   Div1WheelsOff  Div1TailNum  Div2Airport  Div2AirportID Div2AirportSeqID  \\\n",
       "0            NaN          NaN          NaN            NaN              NaN   \n",
       "1            NaN          NaN          NaN            NaN              NaN   \n",
       "2            NaN          NaN          NaN            NaN              NaN   \n",
       "3            NaN          NaN          NaN            NaN              NaN   \n",
       "4            NaN          NaN          NaN            NaN              NaN   \n",
       "\n",
       "  Div2WheelsOn Div2TotalGTime  Div2LongestGTime Div2WheelsOff  Div2TailNum  \n",
       "0          NaN            NaN               NaN           NaN          NaN  \n",
       "1          NaN            NaN               NaN           NaN          NaN  \n",
       "2          NaN            NaN               NaN           NaN          NaN  \n",
       "3          NaN            NaN               NaN           NaN          NaN  \n",
       "4          NaN            NaN               NaN           NaN          NaN  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with a specified encoding\n",
    "df = pd.read_csv(\"cleaned_flight_data.csv\", encoding=\"ISO-8859-1\", low_memory=False)\n",
    "\n",
    "# Display the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing ---\n",
    "# Fill missing values for numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target variable 'DelayCategory': 1 if there was an arrival delay (ArrDelay > 0), 0 if there wasn't\n",
    "df['DelayCategory'] = df.apply(lambda row: 1 if row['ArrDelay'] > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode 'DelayCategory'\n",
    "le = LabelEncoder()\n",
    "df['DelayCategory'] = le.fit_transform(df['DelayCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering (time-related features)\n",
    "df['ArrTime_combined'] = df['ArrTime'] // 100 * 60 + df['ArrTime'] % 100\n",
    "\n",
    "# Time of day: 7 AM to 1 PM window for arrival\n",
    "df['DayArrivalFlight'] = df['ArrTime_combined'].apply(lambda x: 1 if 420 <= x <= 780 else 0)  # 7 AM to 1 PM\n",
    "\n",
    "# Seasonal and time-of-day features\n",
    "# Updated months for seasonal delays: December, February, April, July, August\n",
    "df['HighDelaySeason'] = df['Month'].apply(lambda x: 1 if x in [2, 4, 7, 8, 12] else 0)\n",
    "\n",
    "# Create binary features based on TaxiIn and TaxiOut times\n",
    "df['TaxiIn_Long'] = df['TaxiIn'].apply(lambda x: 1 if x > 10 else 0)\n",
    "df['TaxiOut_Long'] = df['TaxiOut'].apply(lambda x: 1 if x > 10 else 0)\n",
    "\n",
    "# Add the weekend feature (IsWeekend)\n",
    "df['IsWeekend'] = df['DayOfWeek'].apply(lambda x: 1 if x in [5, 6] else 0)  # 5 for Saturday, 6 for Sunday\n",
    "\n",
    "# Add the airline delay flag based on specific airlines (e.g., 'PI', 'AAPS')\n",
    "df['HighDelayAirline'] = df['IATA_CODE_Reporting_Airline'].apply(lambda x: 1 if x in ['PI', 'AA', 'PS'] else 0)\n",
    "\n",
    "# Add binary flag for high-delay weekdays (Wednesday=3, Thursday=4)\n",
    "df['HighDelayWeekday'] = df['DayOfWeek'].apply(lambda x: 1 if x in [3, 4] else 0)\n",
    "\n",
    "# Define the top states\n",
    "high_delay_origin_states = ['CA', 'TX', 'IL', 'FL', 'GA', 'NY', 'CO', 'NC', 'PA', 'AZ']\n",
    "high_delay_dest_states = ['CA', 'TX', 'FL', 'IL', 'GA', 'NY', 'NC', 'CO', 'PA', 'AZ']\n",
    "\n",
    "# Create the features\n",
    "df['HighDelayOriginState'] = df['OriginState'].apply(lambda x: 1 if x in high_delay_origin_states else 0)\n",
    "df['HighDelayDestState'] = df['DestState'].apply(lambda x: 1 if x in high_delay_dest_states else 0)\n",
    "\n",
    "# Features for training\n",
    "features = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek',  'ArrTime_combined',\n",
    "            'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', \n",
    "            'HighDelaySeason', 'DayArrivalFlight', 'TaxiOut_Long', 'TaxiIn_Long', 'IsWeekend', \n",
    "            'HighDelayAirline', 'HighDelayOriginState', 'HighDelayDestState', 'HighDelayWeekday']\n",
    "\n",
    "# Features matrix and target vector\n",
    "X = df[features]\n",
    "y = df['DelayCategory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode any object/categorical columns (just in case)\n",
    "label_encoder = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col].astype(str))\n",
    "\n",
    "# Fill any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# --- Standardization (important for Logistic Regression) ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- Train-test split (Stratified Split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Scaling: Fit scaler on training data and transform both train and test sets ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Apply SMOTE to training data ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# --- XGBoost model without scale_pos_weight (SMOTE already balances classes) ---\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='map',\n",
    "    n_estimators=1000,\n",
    "    tree_method='hist',\n",
    "    verbosity=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- Train the model ---\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# --- Predict and evaluate ---\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# --- Print F1 score ---\n",
    "f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "print(\"XGBoost F1 Score (weighted):\", f1)\n",
    "\n",
    "# --- Print classification report ---\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# --- Print confusion matrix ---\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handle Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 Score (weighted): 0.8038689083163284\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.84    228089\n",
      "           1       0.81      0.72      0.76    171911\n",
      "\n",
      "    accuracy                           0.81    400000\n",
      "   macro avg       0.81      0.79      0.80    400000\n",
      "weighted avg       0.81      0.81      0.80    400000\n",
      "\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[199406  28683]\n",
      " [ 48987 122924]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Train-test split (Stratified Split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Scaling: Fit scaler on training data and transform both train and test sets ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "ratio_of_classes = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# --- XGBoost model with tuned parameters ---\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='map',\n",
    "    n_estimators=1000,\n",
    "    tree_method='hist',\n",
    "    verbosity=0,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=ratio_of_classes\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Get predicted probabilities --- \n",
    "y_pred_prob = xgb_model.predict_proba(X_test_scaled)[:, 1]  # Get probabilities for class 1 (delayed flights)\n",
    "\n",
    "# --- Set a custom threshold for classification --- \n",
    "threshold = 0.5  # You can adjust this value (0.3, 0.4, etc.)\n",
    "y_pred_class = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "# --- Print F1 score ---\n",
    "f1 = f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"XGBoost F1 Score (weighted):\", f1)\n",
    "\n",
    "# --- Print classification report ---\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_class))\n",
    "\n",
    "# --- Print confusion matrix ---\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before Handling Imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 Score (weighted): 0.8057534306186801\n",
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85    228089\n",
      "           1       0.85      0.67      0.75    171911\n",
      "\n",
      "    accuracy                           0.81    400000\n",
      "   macro avg       0.82      0.79      0.80    400000\n",
      "weighted avg       0.82      0.81      0.81    400000\n",
      "\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      "[[208140  19949]\n",
      " [ 56076 115835]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Train-test split (Stratified Split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Scaling: Fit scaler on training data and transform both train and test sets ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- XGBoost model with tuned parameters ---\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='map',\n",
    "    n_estimators=1000,\n",
    "    tree_method='hist',\n",
    "    verbosity=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predict and evaluate ---\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# --- Print F1 score ---\n",
    "f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "print(\"XGBoost F1 Score (weighted):\", f1)\n",
    "\n",
    "# --- Print classification report ---\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# --- Print confusion matrix ---\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1-Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost F1 Score (weighted): 0.8057534306186801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# --- Train-test split (Stratified Split) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# --- Scaling: Fit scaler on training data and transform both train and test sets ---\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- XGBoost model with tuned parameters ---\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='map',\n",
    "    n_estimators=1000,\n",
    "    tree_method='hist',\n",
    "    verbosity=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# --- Predict and evaluate ---\n",
    "y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "# --- Print F1 score ---\n",
    "f1 = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "print(\"XGBoost F1 Score (weighted):\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LightGBM Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81    228010\n",
      "           1       0.73      0.78      0.76    171990\n",
      "\n",
      "    accuracy                           0.78    400000\n",
      "   macro avg       0.78      0.78      0.78    400000\n",
      "weighted avg       0.79      0.78      0.79    400000\n",
      "\n",
      "LightGBM F1 Score: 0.7572742874827674\n",
      "LightGBM Confusion Matrix:\n",
      "[[179149  48861]\n",
      " [ 37411 134579]]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Features matrix and target vector\n",
    "X = df[features]\n",
    "y = df['DelayCategory']\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate class imbalance ratio\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# Create LightGBM datasets\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Set the parameters for LightGBM with imbalance handling\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'scale_pos_weight': scale_pos_weight,  # Handle class imbalance\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[test_data])\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Convert probabilities to binary labels using lower threshold to boost recall for class 1\n",
    "y_pred_binary = (y_pred >= 0.4).astype(int)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(\"--- LightGBM Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Print F1 Score\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "print(\"LightGBM F1 Score:\", f1)\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(\"LightGBM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taxi Details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TaxiIn   TaxiOut  DepDelay  ArrDelay\n",
      "TaxiIn    1.000000  0.049393  0.012460  0.066857\n",
      "TaxiOut   0.049393  1.000000  0.073118  0.257508\n",
      "DepDelay  0.012460  0.073118  1.000000  0.898746\n",
      "ArrDelay  0.066857  0.257508  0.898746  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[['TaxiIn', 'TaxiOut', 'DepDelay', 'ArrDelay']].corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TaxiIn  TaxiOut\n",
      "0     3.0     24.0\n",
      "1     8.0     10.0\n",
      "2     6.0      9.0\n",
      "3     7.0     23.0\n",
      "4     8.0     19.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'TaxiIn' and 'TaxiOut' are columns in the dataset\n",
    "print(df[['TaxiIn', 'TaxiOut']].head())  # Preview the first 5 rows of TaxiIn and TaxiOut data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average delays for flights with TaxiIn > 10 minutes:\n",
      "TaxiIn      16.580352\n",
      "DepDelay     9.038974\n",
      "ArrDelay    12.262727\n",
      "dtype: float64\n",
      "Average delays for flights with TaxiOut > 10 minutes:\n",
      "TaxiOut     17.257763\n",
      "DepDelay     8.584457\n",
      "ArrDelay     7.474424\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set a threshold for TaxiIn or TaxiOut (e.g., greater than 10 minutes)\n",
    "threshold = 10\n",
    "\n",
    "# Filter for rows where TaxiIn or TaxiOut is greater than the threshold\n",
    "high_taxi_in = df[df['TaxiIn'] > threshold]\n",
    "high_taxi_out = df[df['TaxiOut'] > threshold]\n",
    "\n",
    "# Check the delays for these cases\n",
    "high_taxi_in_delays = high_taxi_in[['TaxiIn', 'DepDelay', 'ArrDelay']]\n",
    "high_taxi_out_delays = high_taxi_out[['TaxiOut', 'DepDelay', 'ArrDelay']]\n",
    "\n",
    "# Calculate average delays for these cases\n",
    "avg_delay_taxi_in = high_taxi_in_delays.mean()\n",
    "avg_delay_taxi_out = high_taxi_out_delays.mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Average delays for flights with TaxiIn > {} minutes:\".format(threshold))\n",
    "print(avg_delay_taxi_in)\n",
    "\n",
    "print(\"Average delays for flights with TaxiOut > {} minutes:\".format(threshold))\n",
    "print(avg_delay_taxi_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
